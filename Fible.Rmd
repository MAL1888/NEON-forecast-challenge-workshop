---
title: "MAloiza_fable"
author: '"Mario Loaiza'
date: "2024-02-26"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load packages
library(tidyverse)
library(lubridate)
library(tsibble)
library(fable)
```

```{r get-targets, message=F}
#read in the targets data
targets <- read_csv('https://data.ecoforecast.org/neon4cast-targets/aquatics/aquatics-targets.csv.gz')

# read in the sites data
aquatic_sites <- read_csv("https://raw.githubusercontent.com/eco4cast/neon4cast-targets/main/NEON_Field_Site_Metadata_20220412.csv") |>
  dplyr::filter(aquatics == 1)

lake_sites <- aquatic_sites %>%
  filter(field_site_subtype == 'Lake')

# Filter the targets
targets <- targets %>%
  filter(site_id %in% lake_sites$field_site_id,
         variable == 'temperature')
```

Other variable names can be found at <https://projects.ecoforecast.org/neon4cast-docs/Shared-Forecast-Drivers.html#stage-3>

```{r}
met_variables <- c("air_temperature", "surface_downwelling_longwave_flux_in_air")
```

```{r get-NOAA-past, message = F}

# Past stacked weather
noaa_past_s3 <- neon4cast::noaa_stage3()

noaa_past <- noaa_past_s3  |> 
  dplyr::filter(site_id %in% lake_sites$field_site_id,
                datetime >= ymd('2020-01-01'),
                variable %in% met_variables) |> 
  dplyr::collect()

# aggregate the past to mean values
noaa_past_mean <- noaa_past |> 
  mutate(datetime = as_date(datetime)) |> 
  group_by(datetime, site_id, variable) |> 
  summarize(prediction = mean(prediction, na.rm = TRUE), .groups = "drop") |>
  # convert air temperature to Celsius if it is included in the weather data
  mutate(prediction = ifelse(variable == "air_temperature", prediction - 273.15, prediction)) |>
  pivot_wider(names_from = variable, values_from = prediction) 
```

```{r get-NOAA-future, message = F}
# Future weather
# New forecast only available at 5am UTC the next day
forecast_date <- Sys.Date()
noaa_date <- forecast_date - days(1)

noaa_future_s3 <- neon4cast::noaa_stage2(start_date = as.character(noaa_date))

noaa_future <- noaa_future_s3 |> 
  dplyr::filter(datetime >= forecast_date,
                site_id %in% lake_sites$field_site_id,
                variable %in% met_variables) |> 
  collect()

noaa_future_daily <- noaa_future |> 
  mutate(datetime = as_date(datetime)) |> 
  # mean daily forecasts at each site per ensemble
  group_by(datetime, site_id, parameter, variable) |> 
  summarize(prediction = mean(prediction, na.rm = TRUE), .groups = "drop") |> 
  # convert air temperature to Celsius if it is included in the weather data
  mutate(prediction = ifelse(variable == "air_temperature", prediction - 273.15, prediction)) |> 
  pivot_wider(names_from = variable, values_from = prediction)
```

```{r model-setup}
# Generate a dataframe to fit the model to 
targets_lm <- targets |> 
  pivot_wider(names_from = 'variable', values_from = 'observation') |> 
  left_join(noaa_past_mean, 
            by = c("datetime","site_id"))

# Loop through each site to fit the model
forecast_df <- NULL
```

```{r forecast-loop}
forecast_horizon <- 30
forecast_dates <- seq(from = ymd(forecast_date), to = ymd(forecast_date) + forecast_horizon, by = "day")
n_members <- 31

for(i in 1:length(lake_sites$field_site_id)) {  
  
  curr_site <- lake_sites$field_site_id[i]
  
  site_target <- targets_lm |>
    filter(site_id == curr_site)|>
    na.omit()

  noaa_future_site <- noaa_future_daily |> 
    filter(site_id == curr_site)
  
  #model 1
 # fit <- lm(site_target$temperature ~ site_target$air_temperature + site_target$relative_humidity)
  # Polynomial model
  # Fit polynomial regression model
fit <- lm(site_target$temperature ~ poly(site_target$air_temperature, degree = 2) + 
            poly(site_target$surface_downwelling_shortwave_flux_in_air, degree = 2))
  fit_summary <- summary(fit)
  params_se <- fit_summary$coefficients[,2]
  coeffs <- round(fit$coefficients, 2)
  param_df <- data.frame(beta1 = rnorm(n_members, coeffs[1], params_se[1]),
                       beta2 = rnorm(n_members, coeffs[2], params_se[2]),
                       beta3 = rnorm(n_members, coeffs[3], params_se[3]))

   # Calculate model predictions
 mod <- predict(fit, data = site_target)
 # Calculate model residuals for adding process
 residuals <- mod - site_target$temperature
 # Generate the distribution for residuals
 sigma <- sd(residuals, na.rm = TRUE)
 
  for (t in 1:length(forecast_dates)) {
  
  #pull driver ensemble for the relevant date; here we are using all 30 NOAA ensemble members
  site_drivers <- noaa_future_site %>%
    filter(datetime == forecast_dates[t])
  
  # use linear regression to forecast water temperature for each ensemble member
  # You will need to modify this line of code if you add additional weather variables or change the form of the model
  # The model here needs to match the model used in the lm function above (or what model you used in the fit)
  forecasted_temperature <- param_df$beta1 + site_drivers$air_temperature * param_df$beta2 + 
    site_drivers$relative_humidity * param_df$beta3 + rnorm(n = n_members, mean = 0, sd = sigma)
    
  # put all the relevant information into a tibble that we can bind together
  curr_site_df <- tibble(datetime = rep(forecast_dates[t], times = n_members),
                         site_id = curr_site,
                         parameter = 1:n_members,
                         prediction = forecasted_temperature,
                         variable = "temperature") #Change this if you are forecasting a different variable
  
  forecast_df <- dplyr::bind_rows(forecast_df, curr_site_df)
  
  }
  
  message(curr_site, 'forecast run')
}
```





```{r}
targets <- read_csv('https://data.ecoforecast.org/neon4cast-targets/aquatics/aquatics-targets.csv.gz', show_col_types = FALSE)

max_horizon <- 35
var <- "temperature"
site <- c("BARC") #, "CRAM","LIRO","PRLA", "PRPO", "SUGG", "TOOK")


forecast_starts <- targets |> 
  dplyr::filter(!is.na(observation) & site_id == site & variable == var) |> 
  # Start the day after the most recent non-NA value
  dplyr::summarise(start_date = max(datetime) + lubridate::days(1)) |>  # Date
  dplyr::mutate(h = (Sys.Date() - start_date) + max_horizon,
                h = as.numeric(h)) |>  # Horizon value
  dplyr::ungroup()

forecast_starts

targets_use <- targets |> 
  dplyr::filter(site_id == site,
                variable == var) %>%
  tsibble::as_tsibble(key = c('variable', 'site_id'), index = 'datetime') |> 
  tsibble::fill_gaps()   # add NA values up to today (index)


RW_model <- targets_use |> 
  fabletools::model(RW = fable::RW(observation))

forecast <- RW_model |>  
  fabletools::generate(h = forecast_starts$h, bootstrap = T, times = 200)

RW_forecasts_EFI <- forecast %>%
  rename(parameter = .rep,
         prediction = .sim) %>%
  # For the EFI challenge we only want the forecast for future
  #filter(datetime > Sys.Date()) %>%
  group_by(site_id, variable) %>%
  mutate(reference_datetime = Sys.Date(),
         family = "ensemble",
         model_id = "persistenceRW") %>%
  select(model_id, datetime, reference_datetime, site_id, family, parameter, variable, prediction)

RW_forecasts_EFI |>
  filter(variable == "temperature") |>
  ggplot(aes(x = datetime, y = prediction, group = parameter)) +
  geom_line() + 
  geom_vline(aes(xintercept = reference_datetime), color = "blue") +
  facet_wrap(~site_id)
```

